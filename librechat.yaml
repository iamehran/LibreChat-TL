# librechat.yaml
version: 1.1.4
cache: true

balance:
  enabled: false

endpoints:
  custom:
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "sonar-deep-research",
          "sonar-reasoning-pro",
          "sonar-reasoning",
          "sonar-pro",
          "sonar",
          "r1-1776"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "llama-3-sonar-small-32k-chat"
      summarize: false
      summaryModel: "llama-3-sonar-small-32k-chat"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"

    - name: "Deepseek"
      apiKey: "${DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com/v1"
      models:
        default: ["deepseek-chat", "deepseek-coder", "deepseek-reasoner"]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      modelDisplayLabel: "Deepseek"

    - name: "xai"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default: ["grok-beta"]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "grok-beta"
      summarize: false
      summaryModel: "grok-beta"
      forcePrompt: false
      modelDisplayLabel: "Grok"
